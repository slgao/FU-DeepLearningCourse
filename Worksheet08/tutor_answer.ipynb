{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8bde529",
   "metadata": {},
   "source": [
    "# RNN Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f167ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) <U400\n",
      "(400,) int64\n",
      "(100,) <U1200\n",
      "(100,) int64\n",
      "(250,) <U2000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('rnn-challenge-data.npz', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "    data_x = X['data_x']\n",
    "    data_y = X['data_y']\n",
    "    val_x = X['val_x']\n",
    "    val_y = X['val_y']\n",
    "    test_x = X['test_x']\n",
    "\n",
    "# TRAINING DATA: INPUT (x) AND OUTPUT (y)\n",
    "print(data_x.shape, data_x.dtype)\n",
    "print(data_y.shape, data_y.dtype)\n",
    "\n",
    "# VALIDATION DATA: INPUT (x) AND OUTPUT (y)\n",
    "print(val_x.shape, val_x.dtype)\n",
    "print(val_y.shape, val_y.dtype)\n",
    "\n",
    "# TEST DATA: INPUT (x) ONLY\n",
    "print(test_x.shape, test_x.dtype)\n",
    "\n",
    "# PREDICT prediction FROM test_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54104c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"A\":0,\"C\":1,\"G\":2,\"T\":3}[\"C\"]#test_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114ec6b",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe6209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca05e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "ctx = {\"device\": device, \"dtype\": torch.float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d97e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1200, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_bases(data):\n",
    "    all_data = []\n",
    "    for x in data:\n",
    "        string = []\n",
    "        for char in x:\n",
    "            string.append({\"A\":0,\"C\":1,\"G\":2,\"T\":3}[char])\n",
    "        tensor = torch.tensor(string)\n",
    "        one_hot = torch.nn.functional.one_hot(tensor)\n",
    "        all_data.append(one_hot)\n",
    "    return torch.stack(all_data).to(**ctx)\n",
    "\n",
    "parse_bases(val_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9679a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(parse_bases(data_x), torch.tensor(data_y))\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "val_data = TensorDataset(parse_bases(val_x), torch.tensor(val_y))\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=100,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81622e9",
   "metadata": {},
   "source": [
    "## Define LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b406634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm = torch.nn.LSTM(\n",
    "#    input_size=4, \n",
    "#    hidden_size=5, \n",
    "#    batch_first=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c92d9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_outputs, (final_h, final_c) = lstm.forward(train_data[:2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df34b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_h[0,:,:], all_outputs[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "174f0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size=4, hidden_size=5, batch_first=True)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        all_outputs, (last_hidden, last_cell) = self.lstm.forward(x)\n",
    "        return self.softmax(all_outputs.sum(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed3f6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(log_prob, category):\n",
    "    return (log_prob.argmax(dim=-1) == category).sum() / len(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743eda7",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "597bf8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0d516e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = torch.nn.NLLLoss()\n",
    "optim = torch.optim.Adam(rnn.parameters(), lr=1e-2)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=100, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bda6930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9e4166c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223b50108f4b4868bec2bccdcc53b70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0      Accuracy: 100%    Best Accuracy: 0%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5814b203bdd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/public/kraemea88/software/anaconda3/envs/june/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/public/kraemea88/software/anaconda3/envs/june/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    \n",
    "    # Training\n",
    "    rnn.train(True)\n",
    "    for seq, category in train_loader:\n",
    "        optim.zero_grad()\n",
    "        result = rnn.forward(seq)\n",
    "        loss = nll(result, category)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    # Validation\n",
    "    rnn.train(False)\n",
    "    for seq, category in val_loader:\n",
    "        result = rnn.forward(seq)\n",
    "        acc = accuracy(result, category).item()\n",
    "        print(f\"Epoch: {epoch}      \"\n",
    "              f\"Accuracy: {100*acc:.0f}%    \"\n",
    "              f\"Best Accuracy: {100*best_accuracy:.0f}%\",\n",
    "              end=\"\\r\"\n",
    "             )\n",
    "        if acc >= best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            torch.save(rnn.state_dict(), \"best_model.pt\")\n",
    "        \n",
    "    #scheduler.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731bdd21",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31881233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_rnn = RNN()\n",
    "loaded_rnn.load_state_dict(torch.load(\"best_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22b85dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_rnn.forward(parse_bases(test_x)).argmax(dim=-1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "171c2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
    "assert prediction.ndim == 1\n",
    "assert prediction.shape[0] == 250\n",
    "\n",
    "# AND SAVE EXACTLY AS SHOWN BELOW\n",
    "np.save('prediction_m2m.npy', prediction.astype(int))\n",
    "\n",
    "# MAKE SURE THAT THE FILE HAS THE CORRECT FORMAT\n",
    "def validate_prediction_format():\n",
    "    loaded = np.load('prediction_m2m.npy')\n",
    "    assert loaded.shape == (250, )\n",
    "    assert loaded.dtype == int\n",
    "    assert (loaded <= 4).all()\n",
    "    assert (loaded >= 0).all()\n",
    "validate_prediction_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50e505bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 1, 1, 0, 4, 2, 0, 4, 2, 4, 3, 3, 2, 0, 3, 3, 2, 3, 2, 0, 4,\n",
       "       2, 4, 0, 3, 2, 0, 1, 4, 1, 1, 1, 1, 0, 0, 4, 3, 1, 3, 2, 2, 2, 4,\n",
       "       3, 4, 1, 0, 1, 0, 1, 2, 4, 4, 3, 0, 0, 4, 4, 2, 1, 2, 3, 0, 3, 1,\n",
       "       2, 2, 4, 3, 3, 4, 2, 3, 3, 1, 1, 4, 4, 0, 1, 0, 0, 1, 2, 0, 4, 0,\n",
       "       4, 2, 3, 3, 2, 3, 2, 3, 4, 1, 2, 1, 2, 4, 2, 1, 0, 3, 3, 1, 3, 3,\n",
       "       0, 1, 1, 0, 4, 4, 2, 0, 1, 4, 2, 0, 4, 2, 3, 2, 4, 0, 1, 0, 2, 4,\n",
       "       0, 1, 2, 0, 4, 2, 2, 1, 3, 0, 1, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 3,\n",
       "       3, 4, 4, 4, 2, 1, 1, 0, 3, 1, 1, 1, 2, 2, 1, 3, 4, 4, 1, 3, 1, 3,\n",
       "       4, 0, 1, 2, 4, 3, 0, 4, 2, 1, 3, 1, 4, 3, 2, 3, 1, 0, 0, 0, 4, 2,\n",
       "       4, 2, 4, 3, 2, 1, 1, 4, 3, 1, 4, 0, 1, 1, 1, 1, 0, 3, 4, 3, 1, 3,\n",
       "       4, 3, 1, 3, 1, 0, 2, 4, 2, 3, 0, 4, 4, 3, 0, 2, 3, 3, 3, 3, 0, 4,\n",
       "       0, 4, 3, 0, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57485fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "other = np.array([2, 4, 1, 1, 0, 4, 2, 0, 4, 2, 4, 3, 3, 2, 0, 3, 4, 2, 3, 2, 0, 4,\n",
    "       2, 4, 0, 3, 2, 0, 1, 4, 1, 1, 1, 1, 0, 0, 4, 3, 1, 3, 2, 2, 2, 4,\n",
    "       3, 4, 1, 0, 1, 0, 1, 2, 4, 4, 3, 0, 0, 4, 4, 2, 1, 2, 3, 2, 3, 1,\n",
    "       2, 2, 4, 4, 3, 4, 2, 3, 3, 1, 1, 4, 4, 0, 1, 0, 0, 1, 2, 0, 4, 0,\n",
    "       4, 2, 3, 4, 2, 3, 2, 3, 4, 1, 2, 1, 2, 4, 2, 1, 0, 3, 3, 2, 3, 3,\n",
    "       0, 1, 1, 0, 4, 4, 2, 0, 1, 4, 2, 0, 4, 2, 3, 2, 4, 0, 1, 0, 2, 4,\n",
    "       0, 1, 2, 0, 4, 2, 2, 1, 3, 0, 1, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 3,\n",
    "       3, 4, 4, 4, 2, 1, 1, 0, 3, 1, 1, 1, 2, 2, 1, 3, 4, 4, 1, 4, 1, 3,\n",
    "       4, 0, 1, 2, 4, 3, 0, 4, 2, 1, 3, 1, 4, 3, 2, 3, 1, 0, 0, 0, 4, 2,\n",
    "       4, 2, 4, 3, 2, 1, 1, 4, 3, 1, 4, 0, 1, 1, 1, 1, 0, 3, 4, 3, 1, 3,\n",
    "       4, 3, 1, 3, 1, 0, 2, 4, 2, 3, 0, 4, 4, 3, 0, 2, 3, 3, 3, 4, 0, 4,\n",
    "       0, 4, 3, 0, 2, 2, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cbb8393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement: 97%\n"
     ]
    }
   ],
   "source": [
    "ratio = (prediction == other).sum() / len(other)\n",
    "print(f\"Agreement: {100*ratio:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5ad8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}