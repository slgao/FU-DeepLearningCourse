{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a66c401-3ddd-4b1f-87a9-546beba5f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "def load_data(data_name):\n",
    "    with np.load(data_name) as fh:\n",
    "        data_x = fh['data_x']\n",
    "        data_y = fh['data_y']\n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "\n",
    "## Model definition\n",
    "## Encoder\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    \"\"\"Documentation for Encoder\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.e1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.e2 = torch.nn.Linear(hidden_dim, 2*hidden_dim)\n",
    "        self.e3 = torch.nn.Linear(2*hidden_dim, latent_dim)\n",
    "        self.e4 = torch.nn.Linear(2*hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.e1(x))\n",
    "        x = F.leaky_relu(self.e2(x))\n",
    "        mean = self.e3(x)\n",
    "        log_variance = self.e4(x)\n",
    "        return mean, log_variance\n",
    "\n",
    "\n",
    "## Decoder\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    \"\"\"Documentation for Decoder\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d1 = torch.nn.Linear(latent_dim, 2*hidden_dim)\n",
    "        self.d2 = torch.nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.d3 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.d1(x))\n",
    "        x = F.leaky_relu(self.d2(x))\n",
    "        output = torch.sigmoid(self.d3(x))        \n",
    "        return output\n",
    "\n",
    "\n",
    "## VAE\n",
    "\n",
    "\n",
    "class VAE(torch.nn.Module):\n",
    "    \"\"\"Documentation for VAE\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "\n",
    "    def reparameterization(self, mean, log_variance):\n",
    "        variance = torch.exp(.5 * log_variance)\n",
    "        epsilon = torch.randn_like(variance).to(DEVICE)\n",
    "        z = mean + variance * epsilon\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, log_variance = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, log_variance)\n",
    "        output = self.Decoder(z)\n",
    "        return output, mean, log_variance\n",
    "\n",
    "\n",
    "## Loss function\n",
    "\n",
    "def loss_func(output, x, mean, log_variance):\n",
    "    loss_reproduction = F.binary_cross_entropy(output, x, reduction='sum')\n",
    "    kld = -.5 * torch.sum(1 + log_variance - mean.pow(2) - log_variance.exp())\n",
    "    return loss_reproduction + kld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa3fec12-ea26-42f1-a256-78102da8c586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 784) (20000,)\n"
     ]
    }
   ],
   "source": [
    "data_name = 'vae-cvae-challenge.npz'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x_dim = 784\n",
    "batch_size = 1024\n",
    "hidden_dim = 256\n",
    "latent_dim = 2\n",
    "epochs = 300\n",
    "lr = .001\n",
    "# load the data\n",
    "data_x, data_y = load_data(data_name)\n",
    "print(data_x.shape, data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a7da4e-ee45-437b-9d9f-ef7e938da638",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data_x, data_y, test_size=.33)\n",
    "data_train = torch.from_numpy(x_train)\n",
    "label_train = torch.from_numpy(y_train)\n",
    "data_test = torch.from_numpy(x_test)\n",
    "label_test = torch.from_numpy(y_test)\n",
    "dataset_test = TensorDataset(data_test, label_test)\n",
    "\n",
    "dataset_train = TensorDataset(data_train, label_train)   \n",
    "dl_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "130e2e69-c8f6-4f85-ae6a-cc7fc220f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(x_dim, hidden_dim, latent_dim)\n",
    "decoder = Decoder(latent_dim, hidden_dim, x_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "vae = vae.to(DEVICE)\n",
    "optimizer = Adam(vae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7d40036-b07b-472f-b107-a5f58c10ad77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                 | 1/300 [00:00<01:08,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 393.60636006868805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                 | 2/300 [00:00<01:03,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 222.2914644388052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                 | 3/300 [00:00<01:05,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 211.4545308626615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                                | 5/300 [00:01<01:02,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 206.05731494610126\n",
      " training loss -- 202.16491655203012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                | 6/300 [00:01<00:59,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 198.44672100360577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                | 7/300 [00:01<01:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 195.49705784137433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▏                                                                               | 8/300 [00:01<01:01,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 193.06100258460413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                               | 9/300 [00:01<01:02,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 189.84704597179706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                              | 11/300 [00:02<01:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 184.75047397613525\n",
      " training loss -- 181.0928451831524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                             | 12/300 [00:02<00:58,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 178.67774882683386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                             | 13/300 [00:02<01:03,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss -- 176.407762160668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e96239e1d294>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# unsupervised.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sgao0001\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sgao0001\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sgao0001\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sgao0001\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sgao0001\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sgao0001\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    losses = 0\n",
    "    # unsupervised.\n",
    "    for idx, (x, _) in enumerate(dl_train):\n",
    "        x = x.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output, mean, log_variance = vae(x)\n",
    "        loss = loss_func(output, x, mean, log_variance)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        if x.shape[0] < batch_size:\n",
    "            loss_list += [loss.item() / x.shape[0]]\n",
    "        else:\n",
    "            loss_list += [loss.item() / batch_size]\n",
    "    #print(f' training loss -- {losses / (idx * batch_size)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a85dfb4-b67f-44ce-bc4f-5d6728284b16",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52a89e-acbb-43ac-8db8-3bd9ee0b4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), \"vae_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fac9f5-b421-46b1-bfc5-f53a61fd2224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507735ef-01da-4c2c-8043-244e3718415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# visualize losses\n",
    "f, ax = plt.subplots(figsize=(16, 5))\n",
    "ax.plot(loss_list)\n",
    "ax.title.set_text(\"Train loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf501d-8f8d-4802-9506-ac8620aa6016",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7e2b68-71f9-404a-8af8-f4b47e42bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(Encoder(x_dim, hidden_dim, latent_dim),Decoder(latent_dim, hidden_dim, x_dim))\n",
    "vae.load_state_dict(torch.load(\"vae_model\"))\n",
    "vae = vae.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5cda6-67ce-4699-a970-22a504a0588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.cla()\n",
    "fig, axe = plt.subplots(figsize=(16, 10))\n",
    "data_test = data_test.to(DEVICE)\n",
    "mu, log_variance = vae.Encoder(data_test)\n",
    "mu_x = mu.cpu().detach().numpy()[:, 0]\n",
    "mu_y = mu.cpu().detach().numpy()[:, 1]\n",
    "labels = label_test.detach().numpy()\n",
    "plt.scatter(mu_x, mu_y, c=labels, cmap=plt.cm.get_cmap('Spectral', 10), alpha=1, edgecolors='black')\n",
    "#plt.xlim(np.percentile(mu_x, 0.1), np.percentile(mu_y, 99.9))\n",
    "#plt.ylim(np.percentile(mu_y, 0.1), np.percentile(mu_y, 99.9))\n",
    "plt.colorbar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979d557-7c9d-4c10-aa49-58903a22c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, _, _ = vae(data_test)\n",
    "grid_x = 6\n",
    "sample_size = grid_x**2\n",
    "ids = np.random.randint(0, samples.shape[0], sample_size)\n",
    "samples = samples[ids].cpu().detach().numpy()\n",
    "fig_dec = plt.figure(figsize=(grid_x, grid_x))\n",
    "gs = gridspec.GridSpec(grid_x, grid_x)\n",
    "gs.update(wspace=0.05, hspace=0.05)\n",
    "for i, sample in enumerate(samples):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    plt.axis('off')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_aspect('equal')\n",
    "    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47a737-4c26-4ca1-92fd-64b51dd9bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data_test\n",
    "grid_x = 6\n",
    "sample_size = grid_x**2\n",
    "samples = samples[ids].cpu().detach().numpy()\n",
    "fig_dec = plt.figure(figsize=(grid_x, grid_x))\n",
    "gs = gridspec.GridSpec(grid_x, grid_x)\n",
    "gs.update(wspace=0.05, hspace=0.05)\n",
    "for i, sample in enumerate(samples):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    plt.axis('off')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_aspect('equal')\n",
    "    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
